{
  "version": "v1.0",
  "train_episodes": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41,
    42,
    43,
    44,
    45,
    46,
    47,
    48,
    49,
    50,
    51,
    52,
    53,
    54,
    55,
    56,
    57,
    58,
    59,
    60,
    61,
    62,
    63,
    64,
    65,
    66,
    67,
    68,
    69,
    70,
    71,
    72,
    73,
    74,
    75,
    76,
    77,
    78,
    79
  ],
  "val_episodes": [
    80,
    81,
    82,
    83,
    84,
    85,
    86,
    87,
    88,
    89
  ],
  "test_episodes": [
    90,
    91,
    92,
    93,
    94,
    95,
    96,
    97,
    98,
    99
  ],
  "random_seed": 42,
  "total_train": 80,
  "total_val": 10,
  "total_test": 10,
  "description": "Fixed split for fair model comparison (LSTM vs GRU)",
  "hyperparameters": {
    "random_seed": 42,
    "recommended_lr": 0.001,
    "recommended_batch_size": 64,
    "recommended_sequence_length": 10,
    "recommended_epochs": 50
  },
  "evaluation_metrics": [
    "MAE (Mean Absolute Error)",
    "MAPE (Mean Absolute Percentage Error)",
    "RMSE (Root Mean Squared Error)",
    "QoS Violation Rate (%)",
    "Latency P95 (ms)",
    "Resource Utilization (%)"
  ],
  "preprocessing_specs": {
    "normalization": "StandardScaler (fit on train, apply to val/test)",
    "feature_selection": "Use same 12 features across all models",
    "sequence_generation": "Sliding window, length=10, no overlap across episodes"
  },
  "comparison_guidelines": {
    "models_to_compare": [
      "GRU",
      "LSTM",
      "Transformer",
      "Baseline"
    ],
    "report_format": "All models evaluated on episodes 90-99",
    "statistical_testing": "Use paired t-test for significance",
    "visualization": "Same y-axis scales for fair visual comparison"
  }
}